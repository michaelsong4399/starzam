{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import lightkurve as lk\n",
    "from astroquery.simbad import Simbad\n",
    "import pandas as pd \n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# #tf\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 475)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/michaelsong/Documents/GitHub/starzam/Data_v3/0.csv',delimiter=',').to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77197, 474)\n"
     ]
    }
   ],
   "source": [
    "all_data = np.empty((1,475))\n",
    "for i in range(1609):\n",
    "  try:\n",
    "    all_data = np.concatenate((all_data,pd.read_csv('/Users/michaelsong/Documents/GitHub/starzam/Data_v3/'+str(i)+'.csv',delimiter=',').to_numpy()), axis=0)\n",
    "  except:\n",
    "    continue\n",
    "all_data = all_data[1:].T[1:].T\n",
    "print(all_data.shape)\n",
    "# pd.read_csv('/content/drive/MyDrive/Research - Yihong Song and Rohit Prasanna/Yihong/Data_v2/0.csv',delimiter=',').to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.57137000e+05 4.75100000e+03 2.38300000e+00 ... 5.85052317e+00\n",
      "  9.69580351e+00 7.87920306e+00]\n",
      " [7.57137000e+05 4.75100000e+03 2.38300000e+00 ... 4.51275398e+00\n",
      "  4.17921295e+00 5.35710573e+00]\n",
      " [7.57137000e+05 4.75100000e+03 2.38300000e+00 ... 2.39391900e+00\n",
      "  3.23821209e+00 3.50633041e+00]\n",
      " ...\n",
      " [1.24553570e+07 4.63300000e+03 2.35500000e+00 ... 7.22105298e+00\n",
      "  6.25722946e+00 6.97677380e+00]\n",
      " [1.24553570e+07 4.63300000e+03 2.35500000e+00 ... 5.24570461e+00\n",
      "  6.56183340e+00 5.67633786e+00]\n",
      " [1.24553570e+07 4.63300000e+03 2.35500000e+00 ... 5.01127168e+00\n",
      "  5.92280860e+00 4.84215917e+00]]\n",
      "[4751. 4751. 4751. ... 4633. 4633. 4633.]\n"
     ]
    }
   ],
   "source": [
    "print(all_data)\n",
    "print(all_data.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_observations(data):\n",
    "    kic = 0\n",
    "    res = np.empty((1,474))\n",
    "    for i in range(len(data)):\n",
    "        if(data[i][0]!=kic):\n",
    "            kic = data[i][0]\n",
    "            res = np.vstack((res,data[i]))\n",
    "    return res\n",
    "\n",
    "# iso_data = isolate_observations(all_data).T[:10].T\n",
    "# print(iso_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77197, 108) (77197, 2)\n",
      "(77197,)\n",
      "[4751. 4751. 4751. ... 4633. 4633. 4633.]\n",
      "[1.         4.20230387 5.08429584 2.8705257  3.03384979 3.09656549\n",
      " 3.75869284 3.02637558 3.31568472 3.41449566 3.89064309 4.46707678\n",
      " 2.84617214 4.34024907 4.44872399 5.03072533 2.98603345 3.9704044\n",
      " 4.04709734 2.80572554 2.4993625  2.28989815 2.79916182 3.17560122\n",
      " 2.09595172 1.70385558 2.22020202 1.28954937 1.33034144 1.36817343\n",
      " 1.44803374 1.22482013 1.17279956 1.15741269 1.02777875 0.83268147\n",
      " 1.07621558 1.01634899 1.04705778 0.75180739 0.98345645 0.52860498\n",
      " 0.64266898 0.91150894 0.64917226 0.72432438 0.53779949 0.42462443\n",
      " 0.3537338  0.4926552  0.78995761 0.55776332 0.57220055 0.57275563\n",
      " 0.49731549 0.43799971 0.4458369  0.45464592 0.62300697 0.3417187\n",
      " 0.4578065  0.49357301 0.48549321 0.46430902 0.59852467 0.39175011\n",
      " 0.46451555 0.35469993 0.4856069  0.31489359 0.29580494 0.37052073\n",
      " 0.34718435 0.3317955  0.37470149 0.33784652 0.34154617 0.28003836\n",
      " 0.34905947 0.35260452 0.31909339 0.28457844 0.3655531  0.28609421\n",
      " 0.27287525 0.32178996 0.29187161 0.32573694 0.31521757 0.29602352\n",
      " 0.31155542 0.26815045 0.25072878 0.32193828 0.30793917 0.17823744\n",
      " 0.27003274 0.21051989 0.27442812 0.3138275  0.23659274 0.21468438\n",
      " 0.22612513 0.26652898 0.21920029 0.26014059 0.21784751 0.26493008]\n"
     ]
    }
   ],
   "source": [
    "def extract_xy(all_data):\n",
    "    all_x = all_data.T[3:111].T\n",
    "    all_y = all_data.T[1:3].T\n",
    "    print(all_x.shape,all_y.shape)\n",
    "    teff_y = all_y.T[0].T\n",
    "    print(teff_y.shape)\n",
    "    print(teff_y)\n",
    "    print(all_x[1])\n",
    "    return all_x,teff_y\n",
    "\n",
    "all_x,teff_y = extract_xy(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_with_moments(X_train, axes=0, epsilon=1e-8,keep_dims=True):\n",
    "    x = tf.convert_to_tensor(X_train)\n",
    "    mean, variance = tf.nn.moments(x, axes=axes)\n",
    "    x_normed = (x - mean) / tf.sqrt(variance + epsilon) # epsilon to avoid dividing by zero\n",
    "    return x_normed\n",
    "\n",
    "def normalize_x(x):\n",
    "    x = x.T\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i] / np.linalg.norm(x[i])\n",
    "    return x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teff_y = normalize_with_moments(teff_y).numpy()\n",
    "# all_x = normalize_x(all_x)\n",
    "# print(teff_y)\n",
    "# print(all_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         4.20230387 5.08429584 2.8705257  3.03384979 3.09656549\n",
      " 3.75869284 3.02637558 3.31568472 3.41449566 3.89064309 4.46707678\n",
      " 2.84617214 4.34024907 4.44872399 5.03072533 2.98603345 3.9704044\n",
      " 4.04709734 2.80572554 2.4993625  2.28989815 2.79916182 3.17560122\n",
      " 2.09595172 1.70385558 2.22020202 1.28954937 1.33034144 1.36817343\n",
      " 1.44803374 1.22482013 1.17279956 1.15741269 1.02777875 0.83268147\n",
      " 1.07621558 1.01634899 1.04705778 0.75180739 0.98345645 0.52860498\n",
      " 0.64266898 0.91150894 0.64917226 0.72432438 0.53779949 0.42462443\n",
      " 0.3537338  0.4926552  0.78995761 0.55776332 0.57220055 0.57275563\n",
      " 0.49731549 0.43799971 0.4458369  0.45464592 0.62300697 0.3417187\n",
      " 0.4578065  0.49357301 0.48549321 0.46430902 0.59852467 0.39175011\n",
      " 0.46451555 0.35469993 0.4856069  0.31489359 0.29580494 0.37052073\n",
      " 0.34718435 0.3317955  0.37470149 0.33784652 0.34154617 0.28003836\n",
      " 0.34905947 0.35260452 0.31909339 0.28457844 0.3655531  0.28609421\n",
      " 0.27287525 0.32178996 0.29187161 0.32573694 0.31521757 0.29602352\n",
      " 0.31155542 0.26815045 0.25072878 0.32193828 0.30793917 0.17823744\n",
      " 0.27003274 0.21051989 0.27442812 0.3138275  0.23659274 0.21468438\n",
      " 0.22612513 0.26652898 0.21920029 0.26014059 0.21784751 0.26493008]\n"
     ]
    }
   ],
   "source": [
    "print(all_x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61757, 108) (15440, 108) (61757,) (15440,)\n",
      "(61757, 108) (15440, 108) (61757,) (15440,)\n"
     ]
    }
   ],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(all_x, teff_y, test_size=0.20, random_state=42)\n",
    "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)\n",
    "train_x = np.asarray(train_x).astype('float32')\n",
    "test_x = np.asarray(test_x).astype('float32')\n",
    "train_y = np.asarray(train_y).astype('float32')\n",
    "test_y = np.asarray(test_y).astype('float32')\n",
    "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2048)              223232    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 2,592,177\n",
      "Trainable params: 2,592,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 11:06:48.857928: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-15 11:06:48.857946: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "tf.test.gpu_device_name() # No GPU Sad :v\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "keras.backend.clear_session()\n",
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Conv1D(1024, 1, activation='relu',batch_input_shape=train_x.shape))\n",
    "# model.add(layers.Dense(128))\n",
    "# model.add(layers.Conv1D(32, 1, activation='relu'))\n",
    "# model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "# model.summary()\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Conv1D(filters=16, kernel_size=1, activation='relu', batch_input_shape=(train_x.shape)))\n",
    "\n",
    "#model.add(layers.Embedding(input_dim=64, output_dim=16))\n",
    "#model.add(layers.LSTM(128,dr\n",
    "# opout=0.2,recurrent_dropout=0.2,input_dim=(train_x.shape[2])))\n",
    "#model.add(layers.Conv1D(1024,1,activation='relu',input_shape=(train_x.shape)))\n",
    "#model.add(layers.Conv1D(256,1,activation='relu'))\n",
    "model.add(layers.Dense(2048, activation=\"relu\", input_shape=((108,))))\n",
    "model.add(layers.Dense(1024, activation=\"relu\"))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dense(4, activation=\"relu\"))\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=5, min_lr=0.001)\n",
    "monitor = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, \n",
    "        patience=30, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 11:06:49.128667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-15 11:07:02.160974: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1930/1930 - 15s - loss: 771852.5000 - accuracy: 0.0000e+00 - val_loss: 60016.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "1930/1930 - 14s - loss: 60050.2500 - accuracy: 0.0000e+00 - val_loss: 64590.8945 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "1930/1930 - 14s - loss: 63724.8633 - accuracy: 0.0000e+00 - val_loss: 33562.6680 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "1930/1930 - 14s - loss: 54365.7031 - accuracy: 0.0000e+00 - val_loss: 36572.9297 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "1930/1930 - 14s - loss: 54792.6914 - accuracy: 0.0000e+00 - val_loss: 143311.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "1930/1930 - 14s - loss: 52407.0898 - accuracy: 0.0000e+00 - val_loss: 39030.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "1930/1930 - 14s - loss: 46828.4688 - accuracy: 0.0000e+00 - val_loss: 35333.5391 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "1930/1930 - 14s - loss: 46631.4688 - accuracy: 0.0000e+00 - val_loss: 34675.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "1930/1930 - 14s - loss: 45010.5195 - accuracy: 0.0000e+00 - val_loss: 33361.8242 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "1930/1930 - 14s - loss: 44806.6367 - accuracy: 0.0000e+00 - val_loss: 38988.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "1930/1930 - 14s - loss: 44695.5742 - accuracy: 0.0000e+00 - val_loss: 74370.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "1930/1930 - 14s - loss: 43151.4258 - accuracy: 0.0000e+00 - val_loss: 41425.9531 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "1930/1930 - 14s - loss: 39404.5859 - accuracy: 0.0000e+00 - val_loss: 34312.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "1930/1930 - 14s - loss: 41124.8125 - accuracy: 0.0000e+00 - val_loss: 30944.5332 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "1930/1930 - 14s - loss: 39480.5742 - accuracy: 0.0000e+00 - val_loss: 61615.5039 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "1930/1930 - 14s - loss: 39554.6484 - accuracy: 0.0000e+00 - val_loss: 38017.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "1930/1930 - 14s - loss: 38777.7578 - accuracy: 0.0000e+00 - val_loss: 56095.6016 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "1930/1930 - 14s - loss: 38615.6953 - accuracy: 0.0000e+00 - val_loss: 29693.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "1930/1930 - 14s - loss: 38987.5391 - accuracy: 0.0000e+00 - val_loss: 32953.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "1930/1930 - 14s - loss: 37349.3633 - accuracy: 0.0000e+00 - val_loss: 56710.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "1930/1930 - 14s - loss: 37027.5703 - accuracy: 0.0000e+00 - val_loss: 29257.4980 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "1930/1930 - 14s - loss: 36175.1211 - accuracy: 0.0000e+00 - val_loss: 35301.7695 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "1930/1930 - 14s - loss: 35302.3320 - accuracy: 0.0000e+00 - val_loss: 31721.8906 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "1930/1930 - 14s - loss: 36827.0664 - accuracy: 0.0000e+00 - val_loss: 28770.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "1930/1930 - 14s - loss: 35374.3320 - accuracy: 0.0000e+00 - val_loss: 28854.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "1930/1930 - 14s - loss: 35304.4688 - accuracy: 0.0000e+00 - val_loss: 73819.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "1930/1930 - 14s - loss: 34787.2188 - accuracy: 0.0000e+00 - val_loss: 30148.9531 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "1930/1930 - 14s - loss: 33217.3359 - accuracy: 0.0000e+00 - val_loss: 28891.7754 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "1930/1930 - 14s - loss: 34768.6172 - accuracy: 0.0000e+00 - val_loss: 30100.5059 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "1930/1930 - 14s - loss: 33414.8203 - accuracy: 0.0000e+00 - val_loss: 29830.5586 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "1930/1930 - 14s - loss: 33500.6367 - accuracy: 0.0000e+00 - val_loss: 29389.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "1930/1930 - 14s - loss: 34161.9492 - accuracy: 0.0000e+00 - val_loss: 28500.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "1930/1930 - 14s - loss: 32193.3984 - accuracy: 0.0000e+00 - val_loss: 29515.5137 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "1930/1930 - 14s - loss: 32935.1523 - accuracy: 0.0000e+00 - val_loss: 32537.8730 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "1930/1930 - 14s - loss: 32381.9551 - accuracy: 0.0000e+00 - val_loss: 63074.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "1930/1930 - 14s - loss: 32670.9805 - accuracy: 0.0000e+00 - val_loss: 40832.8047 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "1930/1930 - 14s - loss: 32694.8867 - accuracy: 0.0000e+00 - val_loss: 27648.5645 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "1930/1930 - 14s - loss: 32133.8711 - accuracy: 0.0000e+00 - val_loss: 28759.8379 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "1930/1930 - 14s - loss: 32456.0312 - accuracy: 0.0000e+00 - val_loss: 32506.8105 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "1930/1930 - 14s - loss: 31453.7930 - accuracy: 0.0000e+00 - val_loss: 29528.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "1930/1930 - 14s - loss: 32018.6445 - accuracy: 0.0000e+00 - val_loss: 30442.1914 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "1930/1930 - 14s - loss: 32484.9297 - accuracy: 0.0000e+00 - val_loss: 33753.7305 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "1930/1930 - 14s - loss: 31469.3359 - accuracy: 0.0000e+00 - val_loss: 32157.7285 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "1930/1930 - 14s - loss: 31944.1758 - accuracy: 0.0000e+00 - val_loss: 27890.6797 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "1930/1930 - 14s - loss: 30428.3086 - accuracy: 0.0000e+00 - val_loss: 28698.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "1930/1930 - 13s - loss: 30927.2188 - accuracy: 0.0000e+00 - val_loss: 43542.3789 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "1930/1930 - 13s - loss: 30935.5781 - accuracy: 0.0000e+00 - val_loss: 31307.3945 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "1930/1930 - 13s - loss: 31556.7676 - accuracy: 0.0000e+00 - val_loss: 29792.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "1930/1930 - 13s - loss: 30132.0508 - accuracy: 0.0000e+00 - val_loss: 43567.7852 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "1930/1930 - 14s - loss: 30890.4043 - accuracy: 0.0000e+00 - val_loss: 26994.1953 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "1930/1930 - 14s - loss: 30630.1172 - accuracy: 0.0000e+00 - val_loss: 32915.3828 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "1930/1930 - 14s - loss: 30137.8477 - accuracy: 0.0000e+00 - val_loss: 27986.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "1930/1930 - 14s - loss: 30624.8223 - accuracy: 0.0000e+00 - val_loss: 28708.6914 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "1930/1930 - 14s - loss: 30238.6250 - accuracy: 0.0000e+00 - val_loss: 40365.8047 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "1930/1930 - 14s - loss: 29223.3457 - accuracy: 0.0000e+00 - val_loss: 31143.6094 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "1930/1930 - 14s - loss: 30351.1914 - accuracy: 0.0000e+00 - val_loss: 29814.0430 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "1930/1930 - 14s - loss: 29485.4531 - accuracy: 0.0000e+00 - val_loss: 27893.9414 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "1930/1930 - 14s - loss: 30143.2832 - accuracy: 0.0000e+00 - val_loss: 55875.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "1930/1930 - 14s - loss: 29967.9395 - accuracy: 0.0000e+00 - val_loss: 28276.3105 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "1930/1930 - 14s - loss: 28520.0391 - accuracy: 0.0000e+00 - val_loss: 32728.5879 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "1930/1930 - 14s - loss: 30145.7266 - accuracy: 0.0000e+00 - val_loss: 39634.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "1930/1930 - 14s - loss: 29222.0625 - accuracy: 0.0000e+00 - val_loss: 30923.5117 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "1930/1930 - 14s - loss: 29243.9668 - accuracy: 0.0000e+00 - val_loss: 29159.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "1930/1930 - 14s - loss: 29522.8281 - accuracy: 0.0000e+00 - val_loss: 33442.3984 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "1930/1930 - 14s - loss: 29974.7559 - accuracy: 0.0000e+00 - val_loss: 29080.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "1930/1930 - 14s - loss: 28898.8828 - accuracy: 0.0000e+00 - val_loss: 45114.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "1930/1930 - 14s - loss: 29489.5488 - accuracy: 0.0000e+00 - val_loss: 28351.9453 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "1930/1930 - 14s - loss: 28688.9531 - accuracy: 0.0000e+00 - val_loss: 27605.3301 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "1930/1930 - 14s - loss: 29454.2422 - accuracy: 0.0000e+00 - val_loss: 36475.8398 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "1930/1930 - 14s - loss: 29244.9785 - accuracy: 0.0000e+00 - val_loss: 31542.8809 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "1930/1930 - 14s - loss: 28428.5371 - accuracy: 0.0000e+00 - val_loss: 27098.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "1930/1930 - 14s - loss: 28365.7598 - accuracy: 0.0000e+00 - val_loss: 26796.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "1930/1930 - 14s - loss: 28927.4902 - accuracy: 0.0000e+00 - val_loss: 27501.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "1930/1930 - 14s - loss: 28124.8613 - accuracy: 0.0000e+00 - val_loss: 27622.0332 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "1930/1930 - 14s - loss: 28871.1191 - accuracy: 0.0000e+00 - val_loss: 28626.5371 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "1930/1930 - 14s - loss: 28192.9199 - accuracy: 0.0000e+00 - val_loss: 30581.6836 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "1930/1930 - 13s - loss: 28181.2305 - accuracy: 0.0000e+00 - val_loss: 54142.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "1930/1930 - 14s - loss: 27756.8652 - accuracy: 0.0000e+00 - val_loss: 29675.8809 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "1930/1930 - 13s - loss: 28246.0254 - accuracy: 0.0000e+00 - val_loss: 28464.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "1930/1930 - 14s - loss: 27956.1895 - accuracy: 0.0000e+00 - val_loss: 27266.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "1930/1930 - 14s - loss: 28740.5469 - accuracy: 0.0000e+00 - val_loss: 27961.8730 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "1930/1930 - 14s - loss: 27770.4941 - accuracy: 0.0000e+00 - val_loss: 26876.9551 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "1930/1930 - 14s - loss: 28032.6738 - accuracy: 0.0000e+00 - val_loss: 36750.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "1930/1930 - 14s - loss: 27608.7227 - accuracy: 0.0000e+00 - val_loss: 34593.2852 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "1930/1930 - 14s - loss: 27971.6035 - accuracy: 0.0000e+00 - val_loss: 43311.7578 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "1930/1930 - 14s - loss: 27500.1680 - accuracy: 0.0000e+00 - val_loss: 30481.7617 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "1930/1930 - 14s - loss: 27519.6445 - accuracy: 0.0000e+00 - val_loss: 26823.2559 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "1930/1930 - 14s - loss: 27773.9668 - accuracy: 0.0000e+00 - val_loss: 26902.3984 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "1930/1930 - 14s - loss: 27681.6914 - accuracy: 0.0000e+00 - val_loss: 28399.0410 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "1930/1930 - 14s - loss: 27203.2656 - accuracy: 0.0000e+00 - val_loss: 28998.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "1930/1930 - 14s - loss: 27623.8789 - accuracy: 0.0000e+00 - val_loss: 27236.6602 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "1930/1930 - 14s - loss: 27636.8184 - accuracy: 0.0000e+00 - val_loss: 27796.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "1930/1930 - 14s - loss: 27770.5898 - accuracy: 0.0000e+00 - val_loss: 28361.5879 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "1930/1930 - 14s - loss: 27435.6055 - accuracy: 0.0000e+00 - val_loss: 26797.4492 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "1930/1930 - 14s - loss: 27434.2402 - accuracy: 0.0000e+00 - val_loss: 28022.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "1930/1930 - 14s - loss: 26982.4258 - accuracy: 0.0000e+00 - val_loss: 26665.2793 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "1930/1930 - 14s - loss: 27320.7832 - accuracy: 0.0000e+00 - val_loss: 38470.3672 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "1930/1930 - 14s - loss: 27069.2676 - accuracy: 0.0000e+00 - val_loss: 27913.8145 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "1930/1930 - 14s - loss: 27272.1094 - accuracy: 0.0000e+00 - val_loss: 32769.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "1930/1930 - 14s - loss: 26823.1465 - accuracy: 0.0000e+00 - val_loss: 33940.2148 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "1930/1930 - 14s - loss: 27027.6543 - accuracy: 0.0000e+00 - val_loss: 26703.8711 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "1930/1930 - 14s - loss: 26629.3223 - accuracy: 0.0000e+00 - val_loss: 27069.9629 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "1930/1930 - 14s - loss: 27017.6289 - accuracy: 0.0000e+00 - val_loss: 28172.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "1930/1930 - 14s - loss: 27256.0566 - accuracy: 0.0000e+00 - val_loss: 26932.8496 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "1930/1930 - 14s - loss: 26767.9453 - accuracy: 0.0000e+00 - val_loss: 29820.4609 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "1930/1930 - 14s - loss: 26135.6055 - accuracy: 0.0000e+00 - val_loss: 31841.0254 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "1930/1930 - 14s - loss: 26569.0254 - accuracy: 0.0000e+00 - val_loss: 26773.2617 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "1930/1930 - 14s - loss: 26385.8652 - accuracy: 0.0000e+00 - val_loss: 30883.4805 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "1930/1930 - 14s - loss: 26231.5723 - accuracy: 0.0000e+00 - val_loss: 30855.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "1930/1930 - 14s - loss: 26743.8594 - accuracy: 0.0000e+00 - val_loss: 30064.5508 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "1930/1930 - 13s - loss: 26488.7598 - accuracy: 0.0000e+00 - val_loss: 28482.8984 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "1930/1930 - 13s - loss: 26037.3809 - accuracy: 0.0000e+00 - val_loss: 27902.3516 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "1930/1930 - 14s - loss: 25896.5215 - accuracy: 0.0000e+00 - val_loss: 27084.4609 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "1930/1930 - 14s - loss: 26341.8926 - accuracy: 0.0000e+00 - val_loss: 32009.1836 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "1930/1930 - 14s - loss: 25995.9023 - accuracy: 0.0000e+00 - val_loss: 28572.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "1930/1930 - 14s - loss: 26075.3574 - accuracy: 0.0000e+00 - val_loss: 26327.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "1930/1930 - 14s - loss: 26422.3262 - accuracy: 0.0000e+00 - val_loss: 27228.8223 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "1930/1930 - 14s - loss: 26326.6562 - accuracy: 0.0000e+00 - val_loss: 28435.3574 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "1930/1930 - 14s - loss: 25830.6504 - accuracy: 0.0000e+00 - val_loss: 27935.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "1930/1930 - 14s - loss: 25971.7754 - accuracy: 0.0000e+00 - val_loss: 26498.7363 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "1930/1930 - 14s - loss: 25863.9375 - accuracy: 0.0000e+00 - val_loss: 27365.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "1930/1930 - 14s - loss: 25661.0137 - accuracy: 0.0000e+00 - val_loss: 45334.7461 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "1930/1930 - 14s - loss: 26178.4238 - accuracy: 0.0000e+00 - val_loss: 28582.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "1930/1930 - 14s - loss: 25737.1719 - accuracy: 0.0000e+00 - val_loss: 28110.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "1930/1930 - 14s - loss: 25696.5801 - accuracy: 0.0000e+00 - val_loss: 27402.6113 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "1930/1930 - 14s - loss: 25691.2402 - accuracy: 0.0000e+00 - val_loss: 31424.8496 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "1930/1930 - 14s - loss: 25531.6230 - accuracy: 0.0000e+00 - val_loss: 27201.8223 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "1930/1930 - 14s - loss: 25741.5762 - accuracy: 0.0000e+00 - val_loss: 30652.8164 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "1930/1930 - 14s - loss: 25715.6973 - accuracy: 0.0000e+00 - val_loss: 33383.4492 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "1930/1930 - 14s - loss: 25809.9238 - accuracy: 0.0000e+00 - val_loss: 26995.8789 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "1930/1930 - 14s - loss: 25541.5488 - accuracy: 0.0000e+00 - val_loss: 29551.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "1930/1930 - 14s - loss: 25841.2793 - accuracy: 0.0000e+00 - val_loss: 27958.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "1930/1930 - 14s - loss: 25164.5469 - accuracy: 0.0000e+00 - val_loss: 27227.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "1930/1930 - 14s - loss: 25514.1641 - accuracy: 0.0000e+00 - val_loss: 29675.8105 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "1930/1930 - 14s - loss: 25261.5781 - accuracy: 0.0000e+00 - val_loss: 43231.3984 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "1930/1930 - 14s - loss: 25348.0723 - accuracy: 0.0000e+00 - val_loss: 28483.7773 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "1930/1930 - 14s - loss: 25598.9297 - accuracy: 0.0000e+00 - val_loss: 28552.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "1930/1930 - 14s - loss: 25319.5605 - accuracy: 0.0000e+00 - val_loss: 29669.3242 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "1930/1930 - 14s - loss: 25092.3926 - accuracy: 0.0000e+00 - val_loss: 28331.9023 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "1930/1930 - 14s - loss: 25690.3711 - accuracy: 0.0000e+00 - val_loss: 36911.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "1930/1930 - 14s - loss: 25142.8320 - accuracy: 0.0000e+00 - val_loss: 28520.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "1930/1930 - 14s - loss: 25411.6875 - accuracy: 0.0000e+00 - val_loss: 28234.8516 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "1930/1930 - 14s - loss: 24899.7832 - accuracy: 0.0000e+00 - val_loss: 27848.6660 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "1930/1930 - 14s - loss: 25469.0898 - accuracy: 0.0000e+00 - val_loss: 27670.2266 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "1930/1930 - 14s - loss: 25149.8750 - accuracy: 0.0000e+00 - val_loss: 27088.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "1930/1930 - 14s - loss: 24741.1699 - accuracy: 0.0000e+00 - val_loss: 27021.9590 - val_accuracy: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00146: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, epochs=1000,validation_data=(test_x, test_y),callbacks=[monitor], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/michaelsong/Documents/GitHub/starzam/Models/m4.0/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/Users/michaelsong/Documents/GitHub/starzam/Models/m4.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 11:42:25.848050: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15440,) (61757,)\n",
      "[5076.4453 4859.4136 5010.996  ... 4834.709  5100.9673 4817.1587]\n",
      "[5333. 4781. 4985. ... 4958. 5016. 4755.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_test_y = model.predict(test_x).reshape(-1)\n",
    "pred_train_y = model.predict(train_x).reshape(-1)\n",
    "print(pred_test_y.shape,pred_train_y.shape)\n",
    "print(pred_train_y)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.scatter(train_y,pred_train_y, c='red', alpha=0.5,s=1)\n",
    "\n",
    "plt.scatter(test_y,pred_test_y, c='blue', alpha=0.5,s=1)\n",
    "\n",
    "linex = np.linspace(3000, 7000)\n",
    "liney = linex\n",
    "lineytop = linex+500\n",
    "lineybot = linex-500\n",
    "# Create the plot\n",
    "plt.plot(linex, liney,c=\"green\")\n",
    "plt.plot(linex, lineytop,c=\"red\")\n",
    "plt.plot(linex, lineybot,c=\"red\")\n",
    "\n",
    "\n",
    "plt.xlim(3000, 7000)\n",
    "plt.ylim(3000, 7000)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize1D(data):\n",
    "    return np.divide(np.nan_to_num(data,np.nanmean(data)),np.nanmax(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Sq. Error, Mean Abs. Error\n",
      "0.065643884 0.060897335\n"
     ]
    }
   ],
   "source": [
    "mse = np.sqrt(mean_squared_error(normalize1D(test_y),normalize1D(pred_test_y)))\n",
    "mae = mean_absolute_error(normalize1D(test_y),normalize1D(pred_test_y))\n",
    "print(\"Mean Sq. Error, Mean Abs. Error\")\n",
    "print(mse,mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47065cae1920ebace9a059c93d67134c9a065e51e3ecb9809a1abf9fcf371550"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
